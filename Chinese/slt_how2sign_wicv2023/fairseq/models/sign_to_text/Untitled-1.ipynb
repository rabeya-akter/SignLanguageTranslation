{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self, num_node):\n",
    "        self.num_node = num_node\n",
    "        self.AD, self.AD2, self.bias_mat_1, self.bias_mat_2 = self.normalize_adjacency()\n",
    "        \n",
    "    def normalize_adjacency(self):\n",
    "        self_link = [(i, i) for i in range(self.num_node)]\n",
    "        neighbor_1base = [(0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5),\n",
    "                              (5, 6), (6, 8), (9, 10), (11, 12), (11, 13),\n",
    "                              (13, 15), (15, 17), (15, 19), (15, 21), (17, 19),\n",
    "                              (12, 14), (14, 16), (16, 18), (16, 20), (16, 22),\n",
    "                              (18, 20), (11, 23), (12, 24), (23, 24), (23, 25),\n",
    "                              (24, 26), (25, 27), (26, 28), (27, 29), (28, 30),\n",
    "                              (29, 31), (30, 32), (27, 31), (28, 32)]\n",
    "        neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
    "        edge = self_link + neighbor_link    \n",
    "        A = np.zeros((self.num_node, self.num_node)) # adjacency matrix\n",
    "        for i, j in edge:\n",
    "            A[j, i] = 1\n",
    "            A[i, j] = 1\n",
    "        \n",
    "        A2 = np.zeros((self.num_node, self.num_node)) # second order adjacency matrix\n",
    "        for root in range(A.shape[1]):\n",
    "            for neighbour in range(A.shape[0]):\n",
    "                if A[root, neighbour] == 1:\n",
    "                    for neighbour_of_neigbour in range(A.shape[0]):\n",
    "                        if A[neighbour, neighbour_of_neigbour] == 1:\n",
    "                            A2[root,neighbour_of_neigbour] = 1                 \n",
    "        #AD = self.normalize(A)\n",
    "        #AD2 = self.normalize(A2)\n",
    "        bias_mat_1 = np.zeros(A.shape)\n",
    "        bias_mat_2 = np.zeros(A2.shape)\n",
    "        bias_mat_1 = np.where(A!=0, bias_mat_1, -1e9)\n",
    "        bias_mat_2 = np.where(A2!=0, A2, -1e9)\n",
    "        AD = A.astype('float32')\n",
    "        AD2 = A2.astype('float32')\n",
    "        bias_mat_1 = bias_mat_1.astype('float32')\n",
    "        bias_mat_2 = bias_mat_2.astype('float32')\n",
    "        #AD = tf.convert_to_tensor(AD)\n",
    "        #AD2= tf.convert_to_tensor(AD2)\n",
    "        AD=torch.tensor(AD).to('cuda:0')\n",
    "        AD2=torch.tensor(AD2).to('cuda:0')\n",
    "        #bias_mat_1 = tf.convert_to_tensor(bias_mat_1)\n",
    "        #bias_mat_2 = tf.convert_to_tensor(bias_mat_2)\n",
    "        bias_mat_1=torch.tensor(bias_mat_1).to('cuda:0')\n",
    "        bias_mat_2=torch.tensor(bias_mat_2).to('cuda:0')\n",
    "        return AD, AD2, bias_mat_1, bias_mat_2\n",
    "        \n",
    "    def normalize(self, adjacency):\n",
    "        rowsum = np.array(adjacency.sum(1))\n",
    "        r_inv = np.power(rowsum, -1).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0\n",
    "        r_mat_inv = np.diag(r_inv)\n",
    "        normalize_adj = r_mat_inv.dot(adjacency)\n",
    "        normalize_adj = normalize_adj.astype('float32')\n",
    "        #normalize_adj = tf.convert_to_tensor(normalize_adj)\n",
    "        normalize_adj=torch.tensor(normalize_adj)   \n",
    "        return normalize_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class sgcn(nn.Module):\n",
    "    def __init__(self, AD, AD2,bias_mat_1, bias_mat_2, batch_size=10):\n",
    "        super(sgcn, self).__init__()\n",
    "        self.AD = AD\n",
    "        self.AD2 = AD2\n",
    "        self.batch_size = batch_size\n",
    "        self.num_joints = 33\n",
    "        self.bias_mat_1 = bias_mat_1\n",
    "        self.bias_mat_2 = bias_mat_2\n",
    "        self.bias_mat_1.to('cuda:0')\n",
    "        self.bias_mat_2.to('cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "        #self.conv_lstm1=ConvLSTM(64,33,(1,1),1,True, True, False)\n",
    "        #self.conv_lstm2=ConvLSTM(64,33,(1,1),1,True, True, False)\n",
    "        self.dropout = nn.Dropout2d(p=0.25)\n",
    "        #self.bias_mat_1=torch.zeros((33,33)).to('cuda:0')\n",
    "        #self.bias_mat_2=torch.zeros((33,33)).to('cuda:0')\n",
    "        self.conv1=nn.Conv2d(3, 64, kernel_size=(9, 1), padding=(4, 0)).to('cuda:0')\n",
    "        self.conv2=nn.Conv2d(67, 64, kernel_size=(1, 1)).to('cuda:0')\n",
    "        self.conv3=nn.Conv2d(67, 64, kernel_size=(1, 1)).to('cuda:0')\n",
    "        self.conv4=nn.Conv2d(128, 16, kernel_size=(9, 1), padding=(4, 0),).to('cuda:0')\n",
    "        self.conv5=nn.Conv2d(16, 16, kernel_size=(15, 1), padding=(7, 0)).to('cuda:0')\n",
    "        self.conv6=nn.Conv2d(16, 16, kernel_size=(19, 1), padding=(9, 0)).to('cuda:0')\n",
    "        self.relu=F.relu\n",
    "\n",
    "\n",
    "    def forward(self, Input):\n",
    "        print('Input:', Input.shape)\n",
    "        #k1 = F.relu(nn.Conv2d(Input.shape[1], 64, kernel_size=(9, 1), padding=(4, 0)).to('cuda:0')(Input))\n",
    "        k1 = F.relu(self.conv1(Input))\n",
    "        print('k1:',k1.shape)\n",
    "\n",
    "        k = torch.cat((Input, k1), dim=1)\n",
    "        print('k:',k.shape)\n",
    "\n",
    "        #x1 = F.relu(nn.Conv2d(Input.shape[1] + k1.shape[1], 64, kernel_size=(1, 1)).to('cuda:0')(k))\n",
    "        x1 = self.relu(self.conv2(k))\n",
    "        \n",
    "        gcn_x1 = torch.einsum('vw,ncwt->ncvt', (self.AD, x1))\n",
    "\n",
    "\n",
    "        #y1 = F.relu(nn.Conv2d(k.shape[1], 64, kernel_size=(1, 1)).to('cuda:0')(k))\n",
    "        y1 = F.relu(self.conv3(k))\n",
    "        gcn_y1 = torch.einsum('vw,ncwt->ncvt', (self.AD2, y1))\n",
    "\n",
    "        gcn_1 = torch.cat((gcn_x1, gcn_y1), dim=1)\n",
    "        print('gcn_1:',gcn_1.shape)\n",
    "\n",
    "        #z1 = F.relu(nn.Conv2d(gcn_1.shape[1], 16, kernel_size=(9, 1), padding=(4, 0)).to('cuda:0')(gcn_1))\n",
    "        z1 = F.relu(self.conv4(gcn_1))\n",
    "        z1 = self.dropout(z1)\n",
    "\n",
    "        print('z1:',z1.shape)\n",
    "        #z2 = F.relu(nn.Conv2d(z1.shape[1], 16, kernel_size=(15, 1), padding=(7, 0)).to('cuda:0')(z1))\n",
    "        z2 = F.relu(self.conv5(z1))\n",
    "        z2 = self.dropout(z2)\n",
    "\n",
    "        print('z2:',z2.shape)\n",
    "        #z3 = F.relu(nn.Conv2d(z2.shape[1], 16, kernel_size=(19, 1), padding=(9, 0)).to('cuda:0')(z2))\n",
    "        z3 = F.relu(self.conv6(z2))\n",
    "        z3 = self.dropout(z3)\n",
    "\n",
    "        z = torch.cat((z1, z2, z3), dim=1)\n",
    "\n",
    "        return z\n",
    "\n",
    "class Sgcn_Lstm(nn.Module):\n",
    "    def __init__(self, train_x=None, train_y=None, AD=None, AD2=None, lr=0.0001, epoach=200, batch_size=10):\n",
    "        super(Sgcn_Lstm, self).__init__()\n",
    "        #self.train_x = train_x\n",
    "        #self.train_y = train_y\n",
    "        #self.AD = AD\n",
    "        #self.AD2 = AD2\n",
    "        #self.lr = lr\n",
    "        #self.epoach =epoach\n",
    "        #self.batch_size = batch_size\n",
    "        #self.num_joints = 543\n",
    "        graph=Graph(33)\n",
    "\n",
    "\n",
    "\n",
    "        self.sgcn_1=sgcn(graph.AD, graph.AD2, graph.bias_mat_1, graph.bias_mat_2)\n",
    "        self.sgcn_2=sgcn(graph.AD, graph.AD2, graph.bias_mat_1, graph.bias_mat_2)\n",
    "        self.sgcn_3=sgcn(graph.AD, graph.AD2, graph.bias_mat_1, graph.bias_mat_2)\n",
    "\n",
    "    def lstm(self,x):\n",
    "        x = x.view(x.shape[0], -1, x.shape[1] * x.shape[2])\n",
    "        rec,_ = nn.LSTM(input_size=x.shape[2], hidden_size=256, num_layers=1, batch_first=True, dropout=0.25, bidirectional=False).to('cuda:0')(x)\n",
    "        \"\"\"\n",
    "        rec,_ = nn.LSTM(input_size=x.shape[2], hidden_size=64, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True).to('cuda:0')(x)\n",
    "        rec1,_ = nn.LSTM(input_size=rec.shape[-1], hidden_size=32, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True).to('cuda:0')(rec)\n",
    "        rec2,_ = nn.LSTM(input_size=rec1.shape[-1], hidden_size=32, num_layers=1, batch_first=True, dropout=0.25, bidirectional=True).to('cuda:0')(rec1)\n",
    "        rec3,_ = nn.LSTM(input_size=rec2.shape[-1], hidden_size=256, num_layers=1, batch_first=True, dropout=0.25, bidirectional=False).to('cuda:0')(rec2)\n",
    "        \"\"\"\n",
    "        out=rec\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,3,2,1)\n",
    "        x = self.sgcn_1(x)\n",
    "        y = self.sgcn_2(x)\n",
    "        y = y + x\n",
    "        z = self.sgcn_3(y)\n",
    "        z = z + y\n",
    "        \"\"\"\n",
    "        batch_size, _, _, frame_size = z.size()\n",
    "        z = z.view(batch_size * frame_size, -1)\n",
    "        z=nn.Linear(48 * 33, 256).to('cuda:0')(z)\n",
    "        z=z.view(batch_size,frame_size,-1)\n",
    "        #print('z: ',z.shape)\n",
    "        out=z\n",
    "        \"\"\"\n",
    "\n",
    "        out = self.lstm(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 33, 60])\n",
      "Input: torch.Size([4, 3, 33, 60])\n",
      "k1: torch.Size([4, 64, 33, 60])\n",
      "k: torch.Size([4, 67, 33, 60])\n",
      "gcn_1: torch.Size([4, 128, 33, 60])\n",
      "z1: torch.Size([4, 16, 33, 60])\n",
      "z2: torch.Size([4, 16, 33, 60])\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "from torchviz import make_dot\n",
    "input=torch.randn(4, 60, 33, 3).to('cuda:0')\n",
    "input=input.permute(0,3,2,1)\n",
    "print(input.shape)\n",
    "graph=Graph(33)\n",
    "model=sgcn(graph.AD, graph.AD2, graph.bias_mat_1, graph.bias_mat_2)\n",
    "#model=Sgcn_Lstm()\n",
    "model = model.to('cuda:0')\n",
    "#print(model)\n",
    "\n",
    "# Perform a forward pass\n",
    "output = model(input)\n",
    "\n",
    "# Generate the block diagram\n",
    "#dot=make_dot(output, params=dict(model.named_parameters()),show_saved=True)\n",
    "#dot.save('/media/rmedu/Softwares/RabeyaAkter/slt_how2sign_wicv2023/fairseq/models/sign_to_text/sample_graph.dot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([2, 3, 33, 60])\n",
      "k1: torch.Size([2, 64, 33, 60])\n",
      "k: torch.Size([2, 67, 33, 60])\n",
      "gcn_1: torch.Size([2, 128, 33, 60])\n",
      "z1: torch.Size([2, 16, 33, 60])\n",
      "z2: torch.Size([2, 16, 33, 60])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 33, 60]          1,792\n",
      "├─Conv2d: 1-2                            [-1, 64, 33, 60]          4,352\n",
      "├─Conv2d: 1-3                            [-1, 64, 33, 60]          4,352\n",
      "├─Conv2d: 1-4                            [-1, 16, 33, 60]          18,448\n",
      "├─Dropout2d: 1-5                         [-1, 16, 33, 60]          --\n",
      "├─Conv2d: 1-6                            [-1, 16, 33, 60]          3,856\n",
      "├─Dropout2d: 1-7                         [-1, 16, 33, 60]          --\n",
      "├─Conv2d: 1-8                            [-1, 16, 33, 60]          4,880\n",
      "├─Dropout2d: 1-9                         [-1, 16, 33, 60]          --\n",
      "==========================================================================================\n",
      "Total params: 37,680\n",
      "Trainable params: 37,680\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 74.13\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 3.63\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 3.79\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 33, 60]          1,792\n",
       "├─Conv2d: 1-2                            [-1, 64, 33, 60]          4,352\n",
       "├─Conv2d: 1-3                            [-1, 64, 33, 60]          4,352\n",
       "├─Conv2d: 1-4                            [-1, 16, 33, 60]          18,448\n",
       "├─Dropout2d: 1-5                         [-1, 16, 33, 60]          --\n",
       "├─Conv2d: 1-6                            [-1, 16, 33, 60]          3,856\n",
       "├─Dropout2d: 1-7                         [-1, 16, 33, 60]          --\n",
       "├─Conv2d: 1-8                            [-1, 16, 33, 60]          4,880\n",
       "├─Dropout2d: 1-9                         [-1, 16, 33, 60]          --\n",
       "==========================================================================================\n",
       "Total params: 37,680\n",
       "Trainable params: 37,680\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 74.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 3.63\n",
       "Params size (MB): 0.14\n",
       "Estimated Total Size (MB): 3.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,(3,33,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 48, 33, 60])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Padding length must be divisible by 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_131887/804145729.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Pad the tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtensor1_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtensor2_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/safa/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4171\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Padding length must be divisible by 2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4172\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Padding length too large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Padding length must be divisible by 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have two tensors named tensor1 and tensor2\n",
    "tensor1 = torch.randn(100, 32, 256)\n",
    "tensor2 = torch.randn(200, 32, 256)\n",
    "\n",
    "# Get the maximum sequence length\n",
    "max_seq_len = max(tensor1.shape[0], tensor2.shape[0])\n",
    "\n",
    "# Pad the tensors\n",
    "tensor1_padded = torch.nn.functional.pad(tensor1, pad=(max_seq_len - tensor1.shape[0], 0, 0), mode='constant', value=0)\n",
    "tensor2_padded = torch.nn.functional.pad(tensor2, pad=(max_seq_len - tensor2.shape[0], 0, 0), mode='constant', value=0)\n",
    "\n",
    "# Add the tensors together\n",
    "result_tensor = tensor1_padded + tensor2_padded\n",
    "\n",
    "print(result_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
