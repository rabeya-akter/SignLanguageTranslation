# @package _global_

hydra:
  run:
    dir: ${env:SAVE_DIR}/${env:WANDB_NAME}/hydra_outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

common:
  seed: 48151623
  fp16: False
  wandb_project: ${env:WANDB_PROJECT}

distributed_training:
  heartbeat_timeout: 600

checkpoint:
  save_dir: ${env:SAVE_DIR}/${env:WANDB_NAME}/ckpts/
  no_epoch_checkpoints: True
  save_interval_updates: 200
  keep_interval_updates: 1
  best_checkpoint_metric: sacrebleu
  maximize_best_checkpoint_metric: True
  keep_best_checkpoints: 10
  patience: 100

dataset:
  train_subset: cvpr23.fairseq.mediapipe.train.how2sign  
  valid_subset: cvpr23.fairseq.mediapipe.val.how2sign    
  num_workers: 4
  batch_size: 32
  max_tokens: 20_000                          # 640s @ 25fps
  skip_invalid_size_inputs_valid_test: True

task:
  _name: sign_to_text
  data: ${env:MP_DIR}                         
  max_source_positions: 1024                  # ~41s @ 25fps
  max_target_positions: 1024
  feats_type: "mediapipe"
  data_augmentation: False
  eval_gen_config:
    beam: 5
  eval_bleu: True
  #eval_bleu_args: '{"beam": 5, "max_len_a": 0, "max_len_b": 30, "lenpen": 1.0}'
  pre_tokenizer: moses 
  eval_bleu_config:
    sacrebleu_tokenizer: 13a
    sacrebleu_lowercase: False
    sacrebleu_char_level: False
  eval_chrf: True
  eval_reducedBLEU: True
  eval_reducedchrf: True
  eval_print_samples: True

model:
  _name: sign2text_transformer
  encoder_embed_dim: 512
  encoder_ffn_embed_dim: 1024
  encoder_attention_heads: 8
  encoder_layers: 6
  decoder_embed_dim: 512
  decoder_ffn_embed_dim: 1024
  decoder_attention_heads: 8
  decoder_layers: 6
  decoder_output_dim: 512
  layernorm_embedding: True
  share_decoder_input_output_embed: True
  dropout: 0.2
  attention_dropout: 0.2
  activation_dropout: 0.2
  activation_fn: relu

criterion:
  _name: label_smoothed_cross_entropy
  label_smoothing: 0.1

optimizer:
  _name: adam
  adam_betas: (0.9, 0.98)
  adam_eps: 1e-08

optimization:
  lr: [0.001]
  max_update: 40_000
  update_freq: [1]
  clip_norm: 1

lr_scheduler:
  _name: inverse_sqrt
  warmup_updates: 2000

bpe:
  sentencepiece_model: ${env:SAVE_DIR}/vocab/cvpr23.train.how2sign.unigram7000_pre.model